{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f9a6f2",
   "metadata": {},
   "source": [
    "\n",
    "### Residue–Residue Contact Prediction (ESM2-extended)\n",
    "\n",
    "**Purpose:** a lighter, time-bounded first pass you can run locally to verify end‑to‑end training & testing.\n",
    "\n",
    "### What's included\n",
    "- Load PDBs from `../data/pdb/train` and `../data/pdb/test`.\n",
    "- **Cap to the first 100 train structures** (randomly sampled; change `MAX_TRAIN_FILES`) to keep the first run quick.\n",
    "- Train/val split = **80/20** by PDB file.\n",
    "- Build **binary contact labels** from ATOM Cα distances (< 8 Å).\n",
    "- Embed **ATOM-derived sequences** per chain using a **tiny ESM2** (`facebook/esm2_t6_8M_UR50D`) if available; otherwise a local fallback embedder.\n",
    "- Small hyperparameter sweep (lr, hidden, dropout) → pick best, retrain on full train, save model.\n",
    "- Evaluate on held-out **test** set: **PR-AUC, ROC-AUC, Precision@L/L2/L5**.\n",
    "- Notes on multi-chain handling & robustness (unknown residues, empty chains).\n",
    "\n",
    "> ** This runs fine on CPU. If you want extra speed and have a recent PyTorch, it will auto‑use **MPS** if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4626a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Config (edit as needed)\n",
    "# -------------------------\n",
    "from pathlib import Path\n",
    "import random, warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from Bio.PDB import PDBParser, MMCIFParser, PPBuilder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Folders (relative to this notebook)\n",
    "PDB_TRAIN_DIR = Path(\"../data/pdb/train\")    # training PDBs here\n",
    "PDB_TEST_DIR  = Path(\"../data/pdb/test\")     # test PDBs here\n",
    "\n",
    "# Model + training settings\n",
    "MODEL_ID = \"facebook/esm2_t6_8M_UR50D\"       # tiny ESM2 (downloads once to HF cache)\n",
    "CA_DIST_THRESH = 8.0                         # Å for contact definition\n",
    "VAL_SPLIT = 0.2                              # 80/20 split (by PDB file) inside train folder\n",
    "SEED = 42\n",
    "\n",
    "# ---- FastStart caps ----\n",
    "MAX_TRAIN_FILES = 100                        # cap the number of train PDBs to speed up the first run\n",
    "PAIR_SUBSAMPLE_TRAIN = 50_000                # cap #pairs per structure for training (speed/memory)\n",
    "BATCH_PAIRS = 25_000                         # pairs per optimization step\n",
    "EPOCHS = 2                                   # keep tiny for the first run\n",
    "\n",
    "SAVE_PATH = Path(\"models/rescontact_best.pt\") # final model path\n",
    "\n",
    "# Hyperparameter search space (fast run)\n",
    "HPARAM_GRID = {\n",
    "    \"lr\":       [1e-3],\n",
    "    \"hidden\":   [128],\n",
    "    \"dropout\":  [0.1],\n",
    "}\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# Device (MPS if available)\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Silence harmless Biopython warnings about modified residues (e.g., 'GEK')\n",
    "warnings.filterwarnings(\"ignore\", message=\"Assuming residue .* is an unknown modified amino acid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437fd57e",
   "metadata": {},
   "source": [
    "\n",
    "#### Parsing structures → sequences & contact labels\n",
    "\n",
    "- **Sequences**: ATOM-derived (concatenated polypeptide segments per chain). Unknown/modified residues appear as `X`.\n",
    "- **Contacts**: Cα–Cα distance < 8 Å; pairs must have coordinates for both residues.\n",
    "- **Multi-chain**: per-chain blocks assembled into a block-diagonal map; inter-chain pairs ignored in this fast pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e6a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _parser_for(path: Path):\n",
    "    ext = path.suffix.lower()\n",
    "    if ext == \".pdb\":\n",
    "        return PDBParser(QUIET=True)\n",
    "    if ext in (\".cif\", \".mmcif\"):\n",
    "        return MMCIFParser(QUIET=True)\n",
    "    raise ValueError(f\"Unsupported structure format: {path}\")\n",
    "\n",
    "def load_structure(path: Path):\n",
    "    parser = _parser_for(path)\n",
    "    struct = parser.get_structure(path.stem, str(path))\n",
    "    return struct\n",
    "\n",
    "def extract_atom_seq_by_chain(struct):\n",
    "    \"\"\"Return ATOM-derived sequences per chain (concatenate polypeptides).\"\"\"\n",
    "    seqs = {}\n",
    "    ppb = PPBuilder()  # ATOM-based builder\n",
    "    model = next(iter(struct))  # first model only\n",
    "    for chain in model:\n",
    "        polypeps = list(ppb.build_peptides(chain, aa_only=False))\n",
    "        if not polypeps:\n",
    "            continue\n",
    "        seq = \"\".join([str(pp.get_sequence()) for pp in polypeps])\n",
    "        if seq:\n",
    "            clean = [(ch if ch in \"ACDEFGHIKLMNPQRSTVWY\" else \"X\") for ch in seq]\n",
    "            seqs[chain.id] = \"\".join(clean)\n",
    "    return seqs\n",
    "\n",
    "def extract_ca_coords_by_chain(struct):\n",
    "    ppb = PPBuilder()\n",
    "    chain_coords = {}\n",
    "    for model in struct:\n",
    "        for chain in model:\n",
    "            polypeps = ppb.build_peptides(chain, aa_only=False)\n",
    "            if not polypeps:\n",
    "                continue\n",
    "            coords = []\n",
    "            offset = 0\n",
    "            for pp in polypeps:\n",
    "                for i, res in enumerate(pp):\n",
    "                    ca = res[\"CA\"] if \"CA\" in res else None\n",
    "                    if ca is not None:\n",
    "                        coords.append((offset + i, ca.coord.copy()))\n",
    "                offset += len(pp)\n",
    "            if coords:\n",
    "                chain_coords[chain.id] = coords\n",
    "        break\n",
    "    return chain_coords\n",
    "\n",
    "def contact_map_from_coords(coords, L: int, thresh: float):\n",
    "    import numpy as np\n",
    "    has = np.zeros(L, dtype=bool)\n",
    "    xyz = np.zeros((L, 3), dtype=np.float32)\n",
    "    for i, c in coords:\n",
    "        has[i] = True\n",
    "        xyz[i] = c\n",
    "    idx = np.where(has)[0]\n",
    "    contact = np.zeros((L, L), dtype=bool)\n",
    "    if len(idx) > 0:\n",
    "        sub = xyz[idx]\n",
    "        d = np.sqrt(((sub[:,None,:] - sub[None,:,:])**2).sum(-1))\n",
    "        c = d < thresh\n",
    "        for a, ia in enumerate(idx):\n",
    "            for b, ib in enumerate(idx):\n",
    "                contact[ia, ib] = c[a, b]\n",
    "    return contact, has\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d32f3",
   "metadata": {},
   "source": [
    "\n",
    "#### Embedding sequences (tiny ESM2 or fallback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28eb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FallbackEmbedder(torch.nn.Module):\n",
    "    def __init__(self, dim=64, vocab=26):\n",
    "        super().__init__()\n",
    "        self.emb = torch.nn.Embedding(vocab, dim)\n",
    "        torch.nn.init.xavier_uniform_(self.emb.weight)\n",
    "    def forward(self, seq: str) -> torch.Tensor:\n",
    "        idx = torch.tensor([(ord(ch) % 26) for ch in seq], dtype=torch.long, device=DEVICE)\n",
    "        return self.emb(idx)\n",
    "\n",
    "def try_load_esm2(model_id: str):\n",
    "    try:\n",
    "        from transformers import AutoModel, AutoTokenizer\n",
    "        tok = AutoTokenizer.from_pretrained(model_id, use_fast=True, local_files_only=False)\n",
    "        mdl = AutoModel.from_pretrained(model_id, trust_remote_code=True, local_files_only=False)\n",
    "        mdl.to(DEVICE).eval()\n",
    "        return tok, mdl\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] Could not load {model_id}: {e}\\nUsing FallbackEmbedder.\")\n",
    "        return None, FallbackEmbedder().to(DEVICE).eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_sequence(seq: str, tokenizer, model) -> torch.Tensor:\n",
    "    if len(seq) == 0:\n",
    "        return torch.zeros(0, 64, device=DEVICE)\n",
    "    if tokenizer is None:\n",
    "        return model(seq)\n",
    "    tokens = tokenizer(seq, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    tokens = {k: v.to(DEVICE) for k, v in tokens.items()}\n",
    "    out = model(**tokens)\n",
    "    hidden = out.last_hidden_state[0]\n",
    "    if hidden.shape[0] >= len(seq) + 2:\n",
    "        hidden = hidden[1:1+len(seq)]\n",
    "    return hidden.detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11048ee4",
   "metadata": {},
   "source": [
    "#### Pairwise MLP contact head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8fbc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_pair_batch(H: torch.Tensor, pair_idx: np.ndarray) -> torch.Tensor:\n",
    "    if pair_idx.size == 0:\n",
    "        return torch.empty(0, device=DEVICE)\n",
    "    hi = H[pair_idx[:,0]]\n",
    "    hj = H[pair_idx[:,1]]\n",
    "    feats = torch.cat([hi, hj, torch.abs(hi-hj), hi*hj], dim=-1)\n",
    "    return feats\n",
    "\n",
    "class PairMLP(torch.nn.Module):\n",
    "    def __init__(self, d_in: int, hidden: int = 128, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(d_in, hidden),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden, 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b84a80",
   "metadata": {},
   "source": [
    "#### Process structures → tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c155760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_structs(folder: Path):\n",
    "    pats = (\"*.pdb\",\"*.PDB\",\"*.cif\",\"*.CIF\",\"*.mmcif\",\"*.MMCIF\")\n",
    "    files = []\n",
    "    for pat in pats:\n",
    "        files += list(folder.glob(pat))\n",
    "    return sorted(files)\n",
    "\n",
    "def process_structure(path: Path, tokenizer, esm2_model):\n",
    "    try:\n",
    "        s = load_structure(path)\n",
    "        chain_seqs = extract_atom_seq_by_chain(s)\n",
    "        chain_coords = extract_ca_coords_by_chain(s)\n",
    "        if not chain_seqs:\n",
    "            return None\n",
    "\n",
    "        seqs, chain_ids = [], []\n",
    "        contacts_blocks, masks_blocks, H_blocks = [], [], []\n",
    "\n",
    "        for cid in sorted(chain_seqs.keys()):\n",
    "            seq = chain_seqs[cid]\n",
    "            L = len(seq)\n",
    "            if L == 0:\n",
    "                continue\n",
    "            coords = chain_coords.get(cid, [])\n",
    "            cmat, has = contact_map_from_coords(coords, L, CA_DIST_THRESH)\n",
    "\n",
    "            valid = np.zeros((L, L), dtype=bool)\n",
    "            idx = np.where(has)[0]\n",
    "            for i in idx:\n",
    "                for j in idx:\n",
    "                    if i != j:\n",
    "                        valid[i, j] = True\n",
    "\n",
    "            H = embed_sequence(seq, tokenizer, esm2_model)\n",
    "            if H.shape[0] != L:\n",
    "                continue\n",
    "\n",
    "            H_blocks.append(H)\n",
    "            seqs.append(seq)\n",
    "            chain_ids.extend([cid] * L)\n",
    "            contacts_blocks.append(cmat)\n",
    "            masks_blocks.append(valid)\n",
    "\n",
    "        if not seqs:\n",
    "            return None\n",
    "\n",
    "        Ls = [len(sq) for sq in seqs]\n",
    "        Ltot = sum(Ls)\n",
    "        contact_full = np.zeros((Ltot, Ltot), dtype=bool)\n",
    "        valid_full   = np.zeros((Ltot, Ltot), dtype=bool)\n",
    "\n",
    "        ci = 0\n",
    "        for k, L in enumerate(Ls):\n",
    "            cj = ci + L\n",
    "            contact_full[ci:cj, ci:cj] = contacts_blocks[k]\n",
    "            valid_full[ci:cj, ci:cj]   = masks_blocks[k]\n",
    "            ci = cj\n",
    "\n",
    "        H_full = torch.cat(H_blocks, dim=0).to(DEVICE)\n",
    "        uniq = {c:i for i,c in enumerate(sorted(set(chain_ids)))}\n",
    "        chain_ids_arr = np.array([uniq[c] for c in chain_ids], dtype=np.int64)\n",
    "        return {\n",
    "            \"seq\": \"\".join(seqs),\n",
    "            \"chain_ids\": chain_ids_arr,\n",
    "            \"contact\": contact_full,\n",
    "            \"valid_pair\": valid_full,\n",
    "            \"H\": H_full,\n",
    "            \"pdb_id\": path.stem,\n",
    "            \"path\": str(path),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"[error] {path.name}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d8cb2",
   "metadata": {},
   "source": [
    "#### Training / Evaluation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef800e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_pairs(valid_mask: np.ndarray, max_pairs: Optional[int]) -> np.ndarray:\n",
    "    idx = np.argwhere(valid_mask)\n",
    "    if idx.size == 0:\n",
    "        return idx\n",
    "    if (max_pairs is not None) and (len(idx) > max_pairs):\n",
    "        sel = np.random.choice(len(idx), size=max_pairs, replace=False)\n",
    "        idx = idx[sel]\n",
    "    return idx\n",
    "\n",
    "def train_one_epoch(model, opt, train_structs, pair_cap, batch_pairs=BATCH_PAIRS):\n",
    "    model.train()\n",
    "    tot_loss = 0.0\n",
    "    bce = torch.nn.BCEWithLogitsLoss()\n",
    "    for S in train_structs:\n",
    "        if S is None:\n",
    "            continue\n",
    "        H = S[\"H\"]\n",
    "        contact = torch.from_numpy(S[\"contact\"]).to(DEVICE)\n",
    "        pairs = sample_pairs(S[\"valid_pair\"], pair_cap)\n",
    "        if pairs.size == 0:\n",
    "            continue\n",
    "        for start in range(0, len(pairs), batch_pairs):\n",
    "            sl = pairs[start:start+batch_pairs]\n",
    "            X = build_pair_batch(H, sl)\n",
    "            y = contact[sl[:,0], sl[:,1]].float()\n",
    "            if X.numel() == 0:\n",
    "                continue\n",
    "            logits = model(X)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(logits, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tot_loss += float(loss.detach().cpu())\n",
    "    return tot_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_structs(model, structs):\n",
    "    model.eval()\n",
    "    all_scores, all_labels = [], []\n",
    "    per_pdb_metrics = {}\n",
    "    for S in structs:\n",
    "        if S is None:\n",
    "            continue\n",
    "        H = S[\"H\"]\n",
    "        contact = torch.from_numpy(S[\"contact\"]).to(DEVICE)\n",
    "        idx = np.argwhere(S[\"valid_pair\"])\n",
    "        if idx.size == 0:\n",
    "            continue\n",
    "        X = build_pair_batch(H, idx)\n",
    "        logits = model(X)\n",
    "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        labels = contact[idx[:,0], idx[:,1]].detach().cpu().numpy().astype(int)\n",
    "\n",
    "        try:\n",
    "            ap = average_precision_score(labels, probs)\n",
    "            roc = roc_auc_score(labels, probs)\n",
    "        except Exception:\n",
    "            ap, roc = float(\"nan\"), float(\"nan\")\n",
    "\n",
    "        L = len(S[\"seq\"])\n",
    "        order = np.argsort(-probs)\n",
    "        def prec_at(k):\n",
    "            k = max(1, min(len(order), k))\n",
    "            sel = order[:k]\n",
    "            return labels[sel].mean()\n",
    "        pL   = prec_at(L)\n",
    "        pL2  = prec_at(max(1, L//2))\n",
    "        pL5  = prec_at(max(1, L//5))\n",
    "\n",
    "        per_pdb_metrics[S[\"pdb_id\"]] = dict(pr_auc=ap, roc_auc=roc, p_at_L=pL, p_at_L2=pL2, p_at_L5=pL5)\n",
    "        all_scores.append(probs); all_labels.append(labels)\n",
    "\n",
    "    if not all_scores:\n",
    "        return dict(global_pr_auc=float(\"nan\"), global_roc_auc=float(\"nan\"), per_pdb=per_pdb_metrics)\n",
    "\n",
    "    scores = np.concatenate(all_scores)\n",
    "    labels = np.concatenate(all_labels)\n",
    "    try:\n",
    "        g_ap = average_precision_score(labels, scores)\n",
    "        g_roc = roc_auc_score(labels, scores)\n",
    "    except Exception:\n",
    "        g_ap, g_roc = float(\"nan\"), float(\"nan\")\n",
    "    return dict(global_pr_auc=g_ap, global_roc_auc=g_roc, per_pdb=per_pdb_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97f7f12",
   "metadata": {},
   "source": [
    "#### Build training model: cap→split→sweep→final train→test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cdceedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/.env_res_contact/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/miniconda3/envs/.env_res_contact/lib/python3.11/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/miniconda3/envs/.env_res_contact/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <EB3FF92A-5EB1-3EE8-AF8B-5923C1265422> /opt/miniconda3/envs/.env_res_contact/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/miniconda3/envs/.env_res_contact/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/.env_res_contact/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/.env_res_contact/lib/python3.11/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/.env_res_contact/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedder: EsmModel\n",
      "Found 15000 train files, 500 test files.\n",
      "Capped training files to 100 for a quick run.\n",
      "Split: 80 train / 20 val\n",
      "Processing training structures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embed/train: 100%|██████████| 80/80 [00:45<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing validation structures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embed/val: 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     50\u001b[39m                     best = \u001b[38;5;28mdict\u001b[39m(lr=lr, hidden=hidden, dropout=dropout, score=score)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m best\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m best_cfg = \u001b[43mhyperparam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest config:\u001b[39m\u001b[33m\"\u001b[39m, best_cfg)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Retrain best on full (train + val)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mhyperparam_search\u001b[39m\u001b[34m(train_files, val_files)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS+\u001b[32m1\u001b[39m):\n\u001b[32m     45\u001b[39m     loss = train_one_epoch(model, opt, train_structs, pair_cap=PAIR_SUBSAMPLE_TRAIN)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m val_scores = \u001b[43mevaluate_structs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_structs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m score = val_scores[\u001b[33m\"\u001b[39m\u001b[33mglobal_pr_auc\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[HP] lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, hidden=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, dropout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> val PR-AUC=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/.env_res_contact/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mevaluate_structs\u001b[39m\u001b[34m(model, structs)\u001b[39m\n\u001b[32m     49\u001b[39m X = build_pair_batch(H, idx)\n\u001b[32m     50\u001b[39m logits = model(X)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m probs = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.numpy()\n\u001b[32m     52\u001b[39m labels = contact[idx[:,\u001b[32m0\u001b[39m], idx[:,\u001b[32m1\u001b[39m]].detach().cpu().numpy().astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Load embedder\n",
    "tokenizer, esm2_model = try_load_esm2(MODEL_ID)\n",
    "print(f\"Embedder: {type(esm2_model).__name__}\")\n",
    "\n",
    "# Collect files\n",
    "train_all_files = collect_structs(PDB_TRAIN_DIR)\n",
    "test_files = collect_structs(PDB_TEST_DIR)\n",
    "print(f\"Found {len(train_all_files)} train files, {len(test_files)} test files.\")\n",
    "\n",
    "# Cap training files for the first run\n",
    "if len(train_all_files) > MAX_TRAIN_FILES:\n",
    "    train_all_files = random.sample(train_all_files, MAX_TRAIN_FILES)\n",
    "    print(f\"Capped training files to {len(train_all_files)} for a quick run.\")\n",
    "\n",
    "# Split into train/val\n",
    "train_files, val_files = train_test_split(train_all_files, test_size=VAL_SPLIT, random_state=SEED)\n",
    "print(f\"Split: {len(train_files)} train / {len(val_files)} val\")\n",
    "\n",
    "def hyperparam_search(train_files, val_files):\n",
    "    print(\"Processing training structures...\")\n",
    "    train_structs = []\n",
    "    for p in tqdm(train_files, desc=\"embed/train\"):\n",
    "        S = process_structure(p, tokenizer, esm2_model)\n",
    "        if S is not None:\n",
    "            train_structs.append(S)\n",
    "\n",
    "    print(\"Processing validation structures...\")\n",
    "    val_structs = []\n",
    "    for p in tqdm(val_files, desc=\"embed/val\"):\n",
    "        S = process_structure(p, tokenizer, esm2_model)\n",
    "        if S is not None:\n",
    "            val_structs.append(S)\n",
    "\n",
    "    if not train_structs:\n",
    "        raise ValueError(\"No valid training structures found!\")\n",
    "\n",
    "    d_in = train_structs[0][\"H\"].shape[-1]*4\n",
    "    best = None\n",
    "    for lr in HPARAM_GRID[\"lr\"]:\n",
    "        for hidden in HPARAM_GRID[\"hidden\"]:\n",
    "            for dropout in HPARAM_GRID[\"dropout\"]:\n",
    "                model = PairMLP(d_in=d_in, hidden=hidden, dropout=dropout).to(DEVICE)\n",
    "                opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "                for ep in range(1, EPOCHS+1):\n",
    "                    loss = train_one_epoch(model, opt, train_structs, pair_cap=PAIR_SUBSAMPLE_TRAIN)\n",
    "                val_scores = evaluate_structs(model, val_structs)\n",
    "                score = val_scores[\"global_pr_auc\"]\n",
    "                print(f\"[HP] lr={lr}, hidden={hidden}, dropout={dropout} -> val PR-AUC={score:.4f}\")\n",
    "                if (best is None) or (score > best[\"score\"]):\n",
    "                    best = dict(lr=lr, hidden=hidden, dropout=dropout, score=score)\n",
    "    return best\n",
    "\n",
    "best_cfg = hyperparam_search(train_files, val_files)\n",
    "print(\"Best config:\", best_cfg)\n",
    "\n",
    "# Retrain best on full (train + val)\n",
    "full_files = train_files + val_files\n",
    "print(\"Processing full training set...\")\n",
    "full_structs = []\n",
    "for p in tqdm(full_files, desc=\"embed/full-train\"):\n",
    "    S = process_structure(p, tokenizer, esm2_model)\n",
    "    if S is not None:\n",
    "        full_structs.append(S)\n",
    "\n",
    "d_in = full_structs[0][\"H\"].shape[-1]*4\n",
    "final_model = PairMLP(d_in=d_in, hidden=best_cfg[\"hidden\"], dropout=best_cfg[\"dropout\"]).to(DEVICE)\n",
    "opt = torch.optim.AdamW(final_model.parameters(), lr=best_cfg[\"lr\"])\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    loss = train_one_epoch(final_model, opt, full_structs, pair_cap=PAIR_SUBSAMPLE_TRAIN)\n",
    "    print(f\"[final] epoch {ep} loss {loss:.3f}\")\n",
    "\n",
    "# Save\n",
    "SAVE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save({\n",
    "    \"model_state\": final_model.state_dict(),\n",
    "    \"cfg\": best_cfg,\n",
    "    \"model_class\": \"PairMLP\",\n",
    "    \"d_in\": d_in,\n",
    "}, SAVE_PATH)\n",
    "print(f\"Saved: {SAVE_PATH}\")\n",
    "\n",
    "# Evaluate on test\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_structs = []\n",
    "for p in tqdm(test_files, desc=\"embed/test\"):\n",
    "    S = process_structure(p, tokenizer, esm2_model)\n",
    "    if S is not None:\n",
    "        test_structs.append(S)\n",
    "\n",
    "test_scores = evaluate_structs(final_model, test_structs)\n",
    "print(\"Test (global): PR-AUC={:.4f}, ROC-AUC={:.4f}\".format(\n",
    "    test_scores[\"global_pr_auc\"], test_scores[\"global_roc_auc\"]))\n",
    "\n",
    "# Save per-PDB\n",
    "df_test = pd.DataFrame.from_dict(test_scores[\"per_pdb\"], orient=\"index\").reset_index().rename(columns={\"index\":\"pdb_id\"})\n",
    "df_test.sort_values(\"pr_auc\", ascending=False, inplace=True)\n",
    "results_path = Path(\"results/test_metrics.csv\")\n",
    "results_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "df_test.to_csv(results_path, index=False)\n",
    "print(f\"Saved test results to: {results_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7c7d8",
   "metadata": {},
   "source": [
    "\n",
    "#### Notes & Next steps\n",
    "- Add inter-chain contacts and report intra vs inter separately.\n",
    "- Add long-range only evaluation (e.g., |i−j| ≥ 24).\n",
    "- Integrate template/retrieval channels from similar training structures (for the “use structural data from similar sequences” criterion).\n",
    "- Track time spent per section in `roadmap.txt`.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
