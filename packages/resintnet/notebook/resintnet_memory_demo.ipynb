{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"cba4eb4d","cell_type":"markdown","source":"\n# ResIntNet â€” Kaggle T4 (GPU) â€” v17 (Strong g_mem Path + Route/Align + Nonâ€‘Zero Guards)\n\nThis notebook wires **adaptive memory `g_mem`** directly into the model so that predictions **must** depend on it, and adds **route supervision** (PRS flux) plus **gradientâ€‘alignment** to force the model to attend to edges that lie on predicted routes.\n\n**Highlights**\n- Strong `g_mem` gate (linear with learnable scale; nonâ€‘saturating)\n- Edge skip connection into readout (explicit dependence on edges)\n- No zâ€‘scaling of `g_mem` (kept raw)\n- Route loss + gradient alignment\n- g_mem normalization [0,1] + jitter after PRS adaptation\n- Nonâ€‘zero sensitivity guards (Î”A ablation, toy âˆ‚Ã‚/âˆ‚g_mem)\n- Plain `tqdm` (no ipywidgets needed)\n","metadata":{}},{"id":"1ae446a2","cell_type":"markdown","source":"## âš™ï¸ Runtime setup & config","metadata":{}},{"id":"9caec094-037f-48c6-b7a2-306f134c666e","cell_type":"code","source":"!pip -q install requests biopython networkx numpy scipy pandas tqdm gymnasium torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:15:47.403272Z","iopub.execute_input":"2025-11-14T17:15:47.403583Z","iopub.status.idle":"2025-11-14T17:17:56.152650Z","shell.execute_reply.started":"2025-11-14T17:15:47.403559Z","shell.execute_reply":"2025-11-14T17:17:56.151878Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"id":"58f35668","cell_type":"code","source":"\nimport os, io, json, math, random\nfrom pathlib import Path\nfrom copy import deepcopy\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nfrom tqdm import tqdm\n\nrandom.seed(0); np.random.seed(0); torch.manual_seed(0)\nif torch.cuda.is_available(): torch.cuda.manual_seed_all(0)\n\ndef pick_device():\n    if torch.cuda.is_available(): return torch.device(\"cuda\")\n    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available(): return torch.device(\"mps\")\n    return torch.device(\"cpu\")\n\nDEVICE = pick_device()\nUSE_CUDA = (DEVICE.type == \"cuda\")\nprint(f\"[Device] {DEVICE}; CUDA={'yes' if USE_CUDA else 'no'}\")\n\nfrom contextlib import nullcontext\ndef amp_context():\n    return torch.amp.autocast('cuda') if USE_CUDA else nullcontext()\n\ndef maybe_scaler():\n    return torch.amp.GradScaler('cuda') if USE_CUDA else None\n\nKAGGLE = Path('/kaggle/working').exists()\nROOT = Path('/kaggle/working') if KAGGLE else Path('.')\nCACHE_DIR  = ROOT / \"cache\";  CACHE_DIR.mkdir(parents=True, exist_ok=True)\nPDB_CACHE  = CACHE_DIR / \"pdb\";   PDB_CACHE.mkdir(parents=True, exist_ok=True)\nAFDB_CACHE = CACHE_DIR / \"afdb\";  AFDB_CACHE.mkdir(parents=True, exist_ok=True)\nOUT_DIR    = ROOT / \"outputs\";    OUT_DIR.mkdir(parents=True, exist_ok=True)\n\nRUN_PIPELINE = True\nN_STRUCTURES = 8\nTRAIN_STEPS  = 300\n\nTOPK_PER_NODE   = 6\nMIN_SEQ_SEP     = 2\nSIGMA_CONTACT_A = 8.0\nLAPLACE_EPS = 1e-3\n\nW1_A, W2_DDG, W5_MUT = 1.0, 0.5, 0.05\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:17:56.154220Z","iopub.execute_input":"2025-11-14T17:17:56.154909Z","iopub.status.idle":"2025-11-14T17:17:59.749155Z","shell.execute_reply.started":"2025-11-14T17:17:56.154880Z","shell.execute_reply":"2025-11-14T17:17:59.748506Z"}},"outputs":[{"name":"stdout","text":"[Device] cuda; CUDA=yes\n","output_type":"stream"}],"execution_count":2},{"id":"372a80ee","cell_type":"markdown","source":"## ğŸŒ Connectors (UniProt / PDBe / AFDB)","metadata":{}},{"id":"3eb697a1","cell_type":"code","source":"\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\n\ndef make_session(total=3, backoff=0.5, status=(500,502,503,504)):\n    s = requests.Session()\n    r = Retry(total=total, read=total, connect=total, backoff_factor=backoff, status_forcelist=status)\n    s.mount(\"https://\", HTTPAdapter(max_retries=r))\n    s.mount(\"http://\", HTTPAdapter(max_retries=r))\n    s.headers.update({\"User-Agent\": \"resintnet-kaggle-v17/0.1\"})\n    return s\n\nSESSION = make_session()\n\nBASES = {\n    \"UNIPROT_SEARCH\": \"https://rest.uniprot.org/uniprotkb/search\",\n    \"PDBe_BEST\": \"https://www.ebi.ac.uk/pdbe/api/mappings/best_structures\",\n    \"RCSB_FILES\": \"https://files.rcsb.org/download\",\n    \"AFDB_FILE\": \"https://alphafold.ebi.ac.uk/files/AF-{acc}-F1-model_v4.cif\",\n}\n\ndef uniprot_search(query, fields=(\"accession\",\"id\")):\n    r = SESSION.get(BASES[\"UNIPROT_SEARCH\"], params={\"query\":query, \"format\":\"tsv\", \"fields\":\",\".join(fields), \"size\":500}, timeout=60)\n    r.raise_for_status()\n    return pd.read_csv(io.StringIO(r.text), sep=\"\\t\")\n\ndef pdbe_best_structures(acc):\n    r = SESSION.get(f\"{BASES['PDBe_BEST']}/{acc}\", timeout=60)\n    if r.status_code != 200: return []\n    return r.json().get(acc, [])\n\ndef safe_float(x, default=9.9):\n    try:\n        if x is None: return float(default)\n        return float(x)\n    except Exception:\n        return float(default)\n\ndef download_pdb_cif(pdb_id, out_dir):\n    out = out_dir / f\"{pdb_id.upper()}.cif\"\n    if not out.exists():\n        r = SESSION.get(f\"{BASES['RCSB_FILES']}/{pdb_id.upper()}.cif\", timeout=180)\n        r.raise_for_status(); out.write_text(r.text)\n    return out\n\ndef download_afdb_cif(acc, out_dir):\n    out = out_dir / f\"AF-{acc}-F1-model_v4.cif\"\n    if not out.exists():\n        r = SESSION.get(BASES[\"AFDB_FILE\"].format(acc=acc), timeout=180)\n        if r.status_code != 200: return None\n        out.write_text(r.text)\n    return out\n\ndef collect_uniprot_via_terms(terms, size=5):\n    accs = []\n    for t in terms:\n        try:\n            df = uniprot_search(f\"{t} AND reviewed:true\", fields=(\"accession\",\"id\"))\n            accs.extend(df[\"Entry\"].head(size).tolist())\n        except Exception as e:\n            print(\"UniProt fail:\", t, e)\n    accs = sorted(set(accs))\n    print(\"UniProt candidates:\", len(accs), accs)\n    return accs\n\ndef uniprot_to_structures(accs, cap=100):\n    rows=[]\n    for acc in accs[:cap]:\n        best = pdbe_best_structures(acc)\n        if best:\n            top = max(best, key=lambda r: (safe_float(r.get(\"coverage\",0.0),0.0), -safe_float(r.get(\"resolution\",9.9),9.9)))\n            rows.append({\"uniprot\":acc,\"pdb_id\":str(top.get(\"pdb_id\",\"\")).upper(),\n                         \"chain_id\":top.get(\"chain_id\",\"\"),\"coverage\":top.get(\"coverage\"),\n                         \"resolution\":top.get(\"resolution\"),\"source\":\"PDB\"})\n        else:\n            rows.append({\"uniprot\":acc,\"pdb_id\":None,\"chain_id\":\"\",\n                         \"coverage\":None,\"resolution\":None,\"source\":\"AFDB\"})\n    return pd.DataFrame(rows)\n\ndef download_structures_df(sel_df):\n    paths=[]\n    for _,row in tqdm(sel_df.iterrows(), total=len(sel_df), desc=\"Downloading structures\"):\n        try:\n            if row[\"source\"]==\"PDB\" and row[\"pdb_id\"]:\n                paths.append(str(download_pdb_cif(row[\"pdb_id\"], PDB_CACHE)))\n            else:\n                af=download_afdb_cif(row[\"uniprot\"], AFDB_CACHE)\n                paths.append(str(af) if af else None)\n        except Exception as e:\n            paths.append(None)\n    sel=sel_df.copy(); sel[\"cif_path\"]=paths\n    return sel.dropna(subset=[\"cif_path\"]).reset_index(drop=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:17:59.749923Z","iopub.execute_input":"2025-11-14T17:17:59.750208Z","iopub.status.idle":"2025-11-14T17:17:59.824346Z","shell.execute_reply.started":"2025-11-14T17:17:59.750192Z","shell.execute_reply":"2025-11-14T17:17:59.823793Z"}},"outputs":[],"execution_count":3},{"id":"bb7f3314","cell_type":"markdown","source":"## ğŸ§± CIF â†’ Graph + PRS + adaptive g_mem","metadata":{}},{"id":"dfb052fb","cell_type":"code","source":"\nfrom Bio.PDB import MMCIFParser\nimport networkx as nx\nfrom scipy.spatial.distance import cdist\nfrom scipy import linalg\nimport math\n\nAA3_TO1 = {\"ALA\":\"A\",\"CYS\":\"C\",\"ASP\":\"D\",\"GLU\":\"E\",\"PHE\":\"F\",\"GLY\":\"G\",\"HIS\":\"H\",\"ILE\":\"I\",\n           \"LYS\":\"K\",\"LEU\":\"L\",\"MET\":\"M\",\"ASN\":\"N\",\"PRO\":\"P\",\"GLN\":\"Q\",\"ARG\":\"R\",\"SER\":\"S\",\n           \"THR\":\"T\",\"VAL\":\"V\",\"TRP\":\"W\",\"TYR\":\"Y\"}\nAA1_TO3 = {v:k for k,v in AA3_TO1.items()}\n\ndef parse_cif_to_residues(cif_path, chain_id=None):\n    parser = MMCIFParser(QUIET=True)\n    structure = parser.get_structure(\"prot\", str(cif_path))\n    model = next(structure.get_models())\n    chains = list(model.get_chains())\n    if chain_id and chain_id in {ch.id for ch in chains}:\n        chain = model[chain_id]\n    else:\n        chain = max(chains, key=lambda ch: sum(1 for _ in ch.get_residues()))\n    rows = []\n    for res in chain.get_residues():\n        if \"CA\" not in res: continue\n        atom = res[\"CA\"]\n        rows.append({\"i\": len(rows), \"resseq\": res.id[1], \"resname\": res.get_resname(),\n                     \"x\": float(atom.coord[0]), \"y\": float(atom.coord[1]), \"z\": float(atom.coord[2])})\n    return pd.DataFrame(rows)\n\ndef build_topk_graph(res_df, topk=6, min_sep=2, sigma=8.0):\n    coords = res_df[[\"x\",\"y\",\"z\"]].to_numpy()\n    D = cdist(coords, coords)\n    n = len(res_df); G = nx.Graph()\n    for i,row in res_df.iterrows():\n        G.add_node(int(i), **row.to_dict())\n    for i in range(n):\n        d = D[i].copy(); d[i] = float('inf')\n        for j in range(n):\n            if abs(j-i) < min_sep: d[j] = float('inf')\n        nbrs = np.argsort(d)[:topk]\n        for j in nbrs:\n            w = math.exp(-(D[i,j]**2)/(2*sigma**2))\n            G.add_edge(int(i), int(j), dist=float(D[i,j]), w_contact=float(w), g_mem=1.0)\n    return G\n\ndef laplacian_pinv_weighted(G, eps=1e-3):\n    n = G.number_of_nodes()\n    W = np.zeros((n,n), dtype=float)\n    for i,j,data in G.edges(data=True):\n        wij = float(data.get(\"w_contact\",1.0))\n        if not np.isfinite(wij): wij = 0.0\n        W[i,j]=wij; W[j,i]=wij\n    d = W.sum(axis=1); L = np.diag(d) - W\n    return linalg.pinvh(L + eps*np.eye(n))\n\ndef prs_edge_flux(G, Lp, sources, sinks):\n    n = G.number_of_nodes()\n    b = np.zeros((n,)); b[list(sources)] = 1.0; b[list(sinks)] = -1.0\n    phi = Lp @ b\n    flux = {}\n    for i,j,data in G.edges(data=True):\n        R = data.get(\"dist\", 1.0)\n        R = float(R) if np.isfinite(R) else 1.0\n        flux[(i,j)] = float(abs(phi[i]-phi[j])/(R+1e-6))\n    return flux\n\ndef adapt_conductance(G, flux, alpha=0.2, key=\"g_mem\", base=1.0):\n    for (i,j),f in flux.items():\n        g = G.edges[i,j].get(key, base)\n        if not np.isfinite(g): g = base\n        G.edges[i,j][key] = (1-alpha)*g + alpha*(base + float(f))\n    return G\n\ndef normalize_gmem_01_with_jitter(G, jitter=1e-3):\n    gvals = [float(G.edges[i,j].get(\"g_mem\",1.0)) for i,j in G.edges()]\n    if not gvals: return G\n    gmin, gmax = float(np.min(gvals)), float(np.max(gvals))\n    for i,j in G.edges():\n        g = float(G.edges[i,j].get(\"g_mem\",1.0))\n        if gmax>gmin:\n            g = (g - gmin)/(gmax - gmin)\n        G.edges[i,j][\"g_mem\"] = float(g + np.random.normal(0, jitter))\n    return G\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:17:59.826155Z","iopub.execute_input":"2025-11-14T17:17:59.826376Z","iopub.status.idle":"2025-11-14T17:18:00.264596Z","shell.execute_reply.started":"2025-11-14T17:17:59.826359Z","shell.execute_reply":"2025-11-14T17:18:00.263980Z"}},"outputs":[],"execution_count":4},{"id":"63a71398","cell_type":"markdown","source":"## ğŸ§© Features & tensors (preserve raw g_mem)","metadata":{}},{"id":"9867e05f","cell_type":"code","source":"\ndef aa1_from_resname(res3):\n    AA3_TO1 = {\"ALA\":\"A\",\"CYS\":\"C\",\"ASP\":\"D\",\"GLU\":\"E\",\"PHE\":\"F\",\"GLY\":\"G\",\"HIS\":\"H\",\"ILE\":\"I\",\n               \"LYS\":\"K\",\"LEU\":\"L\",\"MET\":\"M\",\"ASN\":\"N\",\"PRO\":\"P\",\"GLN\":\"Q\",\"ARG\":\"R\",\"SER\":\"S\",\n               \"THR\":\"T\",\"VAL\":\"V\",\"TRP\":\"W\",\"TYR\":\"Y\"}\n    return AA3_TO1.get(str(res3).upper(), \"G\")\n\ndef aa_onehot(aa1):\n    AA = \"ACDEFGHIKLMNPQRSTVWY\"\n    v = np.zeros((20,), dtype=float)\n    if aa1 in AA:\n        v[AA.index(aa1)] = 1.0\n    return v\n\ndef graph_features(G):\n    N = G.number_of_nodes()\n    X = []\n    for i in range(N):\n        nd = G.nodes[i]\n        aa1 = nd.get(\"aa1\", aa1_from_resname(nd.get(\"resname\",\"GLY\")))\n        one = aa_onehot(aa1)\n        pos_frac = i/max(1,N-1)\n        deg = G.degree[i]/max(1,N-1)\n        r = math.sqrt(nd.get(\"x\",0.0)**2 + nd.get(\"y\",0.0)**2 + nd.get(\"z\",0.0)**2)\n        z = nd.get(\"z\",0.0)\n        X.append(np.concatenate([one, [pos_frac, deg, r, z]]))  # 20 + 4 = 24\n    X = np.asarray(X, dtype=float)\n\n    edges = []\n    E = []\n    for i,j,data in G.edges(data=True):\n        edges.append((int(i),int(j),0))\n        E.append([float(data.get(\"dist\",1.0)), float(data.get(\"w_contact\",1.0)), float(data.get(\"g_mem\",1.0))])\n    E = np.asarray(E, dtype=float) if len(E) else np.zeros((0,3), dtype=float)\n    return X, edges, E\n\ndef fit_scalers(graphs):\n    Xs, Es = [], []\n    for (_,_,_,G) in graphs:\n        X_np, edges, E_np = graph_features(G)\n        Xs.append(X_np); Es.append(E_np if len(E_np) else np.zeros((0,3)))\n    Xcat = np.concatenate(Xs, axis=0) if Xs else np.zeros((1,24))\n    Ecat = np.concatenate(Es, axis=0) if Es else np.zeros((1,3))\n    SCALERS = {\n        \"node_mean\": Xcat.mean(axis=0, keepdims=True),\n        \"node_std\":  Xcat.std(axis=0, keepdims=True) + 1e-6,\n        \"edge_mean\": Ecat.mean(axis=0, keepdims=True),\n        \"edge_std\":  Ecat.std(axis=0, keepdims=True) + 1e-6,\n    }\n    return SCALERS\n\ndef normalize_features_keep_gmem(X_np, E_np, node_mean, node_std, edge_mean, edge_std):\n    Xn = (X_np - node_mean) / node_std\n    En = (E_np - edge_mean) / edge_std\n    if E_np.shape[1] >= 3:\n        En[:, 2] = E_np[:, 2]  # keep raw g_mem\n    return Xn, En\n\ndef to_features_device(G, scalers=None, requires_grad=False):\n    X_np, edges, E_np = graph_features(G)\n    if scalers is None:\n        node_mean = np.zeros((1,X_np.shape[1])); node_std = np.ones((1,X_np.shape[1]))\n        edge_mean = np.zeros((1,E_np.shape[1] if E_np.ndim==2 else 3)); edge_std = np.ones((1,E_np.shape[1] if E_np.ndim==2 else 3))\n    else:\n        node_mean, node_std = scalers[\"node_mean\"], scalers[\"node_std\"]\n        edge_mean, edge_std = scalers[\"edge_mean\"], scalers[\"edge_std\"]\n    Xn, En = normalize_features_keep_gmem(X_np, E_np, node_mean, node_std, edge_mean, edge_std)\n    X = torch.tensor(Xn, dtype=torch.float32, device=DEVICE, requires_grad=requires_grad)\n    E = torch.tensor(En, dtype=torch.float32, device=DEVICE, requires_grad=requires_grad)\n    return X, edges, E\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:18:00.265119Z","iopub.execute_input":"2025-11-14T17:18:00.265516Z","iopub.status.idle":"2025-11-14T17:18:00.285967Z","shell.execute_reply.started":"2025-11-14T17:18:00.265495Z","shell.execute_reply":"2025-11-14T17:18:00.285338Z"}},"outputs":[],"execution_count":5},{"id":"9865208c","cell_type":"markdown","source":"## ğŸ§  Model (g_mem gate + edge skip)","metadata":{}},{"id":"2fe908cd","cell_type":"code","source":"\nclass GraphBatchNetAMP(nn.Module):\n    def __init__(self, node_dim, edge_dim, hidden=64):\n        super().__init__()\n        self.node_mlp = nn.Sequential(\n            nn.Linear(node_dim, hidden),\n            nn.ReLU(),\n            nn.Linear(hidden, hidden),\n        )\n        self.edge_mlp = nn.Sequential(\n            nn.Linear(node_dim*2 + edge_dim, hidden),\n            nn.ReLU(),\n            nn.Linear(hidden, hidden),\n        )\n        self.edge_proj = nn.Linear(edge_dim, hidden)\n        self.gate_scale = nn.Parameter(torch.tensor(8.0))\n        self.read = nn.Sequential(\n            nn.Linear(hidden + hidden, 64),\n            nn.ReLU(),\n            nn.Linear(64, 2)\n        )\n\n    def forward_one(self, X, edges, E, edge_dropout=0.1):\n        Hx = torch.relu(self.node_mlp(X))\n\n        g_raw = E[:, 2:3] if E.shape[1] >= 3 else torch.zeros((E.shape[0],1), device=E.device, dtype=E.dtype)\n        gate = torch.clamp(1.0 + self.gate_scale * g_raw, 0.0, 8.0)\n\n        keep = (torch.rand((E.shape[0],), device=E.device) > edge_dropout) if E.shape[0] else torch.tensor([], device=E.device).bool()\n\n        agg = torch.zeros_like(Hx)\n        edge_ctx = torch.zeros_like(Hx[0])\n        for k,(i,j,_) in enumerate(edges):\n            if E.shape[0]==0: break\n            if not keep[k]: continue\n            e_ij = self.edge_mlp(torch.cat([X[i], X[j], E[k]], dim=0))\n            e_ij = torch.relu(e_ij)\n            m_ij = gate[k] * e_ij\n            agg[i] = agg[i] + m_ij\n            agg[j] = agg[j] + m_ij\n            edge_ctx = edge_ctx + gate[k].squeeze(0) * self.edge_proj(E[k])\n        if len(edges)>0:\n            edge_ctx = edge_ctx / (len(edges) + 1e-6)\n\n        H = Hx + agg\n        out = self.read(torch.cat([H.mean(dim=0), edge_ctx], dim=0))\n        return out\n\n    def forward(self, packed_graphs):\n        outs = []\n        for (X,edges,E) in packed_graphs:\n            outs.append(self.forward_one(X, edges, E))\n        return torch.stack(outs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:18:00.286744Z","iopub.execute_input":"2025-11-14T17:18:00.287791Z","iopub.status.idle":"2025-11-14T17:18:00.308578Z","shell.execute_reply.started":"2025-11-14T17:18:00.287769Z","shell.execute_reply":"2025-11-14T17:18:00.307804Z"}},"outputs":[],"execution_count":6},{"id":"ad333b82","cell_type":"markdown","source":"## ğŸ”¬ Inference, scan & influence","metadata":{}},{"id":"97ce9677","cell_type":"code","source":"\nimport networkx as nx\n\ndef clone_graph(G):\n    H = nx.Graph()\n    H.add_nodes_from((n, d.copy()) for n, d in G.nodes(data=True))\n    H.add_edges_from((u, v, d.copy()) for u, v, d in G.edges(data=True))\n    return H\n\ndef set_node_aa(G, i, aa1):\n    aa1 = str(aa1).upper()\n    AA1_TO3 = {'A': 'ALA','C': 'CYS','D': 'ASP','E': 'GLU','F': 'PHE',\n               'G': 'GLY','H': 'HIS','I': 'ILE','K': 'LYS','L': 'LEU',\n               'M': 'MET','N': 'ASN','P': 'PRO','Q': 'GLN','R': 'ARG',\n               'S': 'SER','T': 'THR','V': 'VAL','W': 'TRP','Y': 'TYR'}\n    G.nodes[i][\"aa1\"] = aa1\n    G.nodes[i][\"resname\"] = AA1_TO3.get(aa1, \"GLY\")\n\ndef seq_from_graph(G):\n    s = []\n    for i in range(G.number_of_nodes()):\n        aa1 = G.nodes[i].get(\"aa1\")\n        if not aa1:\n            AA3_TO1 = {\"ALA\":\"A\",\"CYS\":\"C\",\"ASP\":\"D\",\"GLU\":\"E\",\"PHE\":\"F\",\"GLY\":\"G\",\"HIS\":\"H\",\"ILE\":\"I\",\n                       \"LYS\":\"K\",\"LEU\":\"L\",\"MET\":\"M\",\"ASN\":\"N\",\"PRO\":\"P\",\"GLN\":\"Q\",\"ARG\":\"R\",\"SER\":\"S\",\n                       \"THR\":\"T\",\"VAL\":\"V\",\"TRP\":\"W\",\"TYR\":\"Y\"}\n            aa1 = AA3_TO1.get(G.nodes[i].get(\"resname\",\"GLY\"), \"G\")\n        s.append(aa1)\n    return \"\".join(s)\n\n@torch.no_grad()\ndef predict_graph_amp(model, G, scalers=None):\n    X, edges, E = to_features_device(G, scalers=scalers, requires_grad=False)\n    with amp_context():\n        A_hat, ddG_hat = model([(X, edges, E)])[0]\n    return float(A_hat.detach().cpu()), float(ddG_hat.detach().cpu())\n\ndef mutational_scan_amp(model, G, scalers=None, uni=\"UNK\", pdbid=None, chain=None, reward_w=(1.0,0.5,0.05)):\n    base_seq = seq_from_graph(G)\n    A0, ddG0 = predict_graph_amp(model, G, scalers=scalers)\n    rows = []\n    n = G.number_of_nodes()\n    outer = tqdm(range(n), desc=\"Scan positions\", leave=True)\n    for i in outer:\n        wt = base_seq[i]\n        for aa in \"ACDEFGHIKLMNPQRSTVWY\":\n            if aa == wt: continue\n            H = clone_graph(G); set_node_aa(H, i, aa)\n            Lp = laplacian_pinv_weighted(H, eps=LAPLACE_EPS)\n            flux = prs_edge_flux(H, Lp, [i], [min(i+5, n-1)])\n            adapt_conductance(H, flux, alpha=0.1, key=\"g_mem\", base=1.0)\n            normalize_gmem_01_with_jitter(H, jitter=1e-4)\n            A1, ddG1 = predict_graph_amp(model, H, scalers=scalers)\n            dA = A1 - A0\n            ddG_pos = max(0.0, ddG1)\n            reward = reward_w[0]*dA - reward_w[1]*ddG_pos - reward_w[2]*1.0\n            rows.append({\n                \"uniprot\": uni, \"pdb_id\": pdbid, \"chain\": chain,\n                \"pos\": i, \"wt\": wt, \"mut\": aa,\n                \"A_hat\": A1, \"ddG_hat\": ddG1, \"delta_A\": dA,\n                \"stability_penalty\": ddG_pos, \"reward\": reward,\n                \"seq_before\": base_seq, \"seq_after\": base_seq[:i]+aa+base_seq[i+1:]\n            })\n    df = pd.DataFrame(rows).sort_values(\"reward\", ascending=False).reset_index(drop=True)\n    outp = OUT_DIR/ f\"mutational_scan_{uni or pdbid or 'graph'}_amp.csv\"\n    df.to_csv(outp, index=False)\n    return df, outp\n\ndef influence_scores_amp(model, G, scalers=None):\n    X, edges, E = to_features_device(G, scalers=scalers, requires_grad=True)\n    if hasattr(E, \"retain_grad\"): E.retain_grad()\n    with amp_context():\n        A_hat, ddG_hat = model([ (X, edges, E) ])[0]\n    model.zero_grad(set_to_none=True)\n    A_hat.backward(retain_graph=True)\n    gradX_A = X.grad.detach().cpu().numpy() if X.grad is not None else np.zeros((X.shape[0], X.shape[1]))\n    gradE_A = E.grad.detach().cpu().numpy() if E.grad is not None else np.zeros((E.shape[0], E.shape[1]))\n    model.zero_grad(set_to_none=True)\n    X.grad = None; E.grad = None\n    ddG_hat.backward()\n    gradX_D = X.grad.detach().cpu().numpy() if X.grad is not None else np.zeros((X.shape[0], X.shape[1]))\n    gradE_D = E.grad.detach().cpu().numpy() if E.grad is not None else np.zeros((E.shape[0], E.shape[1]))\n\n    node_inf = pd.DataFrame({\n        \"node\": np.arange(X.shape[0]),\n        \"grad_norm_A\": np.linalg.norm(gradX_A, axis=1),\n        \"grad_norm_ddG\": np.linalg.norm(gradX_D, axis=1),\n    })\n    edge_rows = []\n    for k,(i,j,_) in enumerate(edges):\n        gA = float(abs(gradE_A[k,2])) if E.shape[1] >= 3 and k < gradE_A.shape[0] else float(\"nan\")\n        gD = float(abs(gradE_D[k,2])) if E.shape[1] >= 3 and k < gradE_D.shape[0] else float(\"nan\")\n        edge_rows.append({\"i\": i, \"j\": j, \"grad_gmem_A\": gA, \"grad_gmem_ddG\": gD})\n    edge_inf = pd.DataFrame(edge_rows).sort_values(\"grad_gmem_A\", ascending=False).reset_index(drop=True)\n    node_p = OUT_DIR/ f\"influence_nodes_{G.graph.get('uniprot','UNK')}_{G.graph.get('pdb_id','')}_{G.graph.get('chain','')}_amp.csv\"\n    edge_p = OUT_DIR/ f\"influence_edges_{G.graph.get('uniprot','UNK')}_{G.graph.get('pdb_id','')}_{G.graph.get('chain','')}_amp.csv\"\n    node_inf.to_csv(node_p, index=False); edge_inf.to_csv(edge_p, index=False)\n    return node_inf, edge_inf, node_p, edge_p\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:18:00.309589Z","iopub.execute_input":"2025-11-14T17:18:00.309973Z","iopub.status.idle":"2025-11-14T17:18:00.329051Z","shell.execute_reply.started":"2025-11-14T17:18:00.309952Z","shell.execute_reply":"2025-11-14T17:18:00.328311Z"}},"outputs":[],"execution_count":7},{"id":"e17d89fc","cell_type":"markdown","source":"## âœ… Validation sweep & ablations","metadata":{}},{"id":"4d55870f","cell_type":"code","source":"\ndef safe_corr(x,y):\n    x = np.asarray(x); y = np.asarray(y)\n    if len(x) < 2: return np.nan, np.nan\n    xm, ym = x - x.mean(), y - y.mean()\n    pear = float((xm*ym).sum() / (np.sqrt((xm**2).sum()*(ym**2).sum()) + 1e-12))\n    rx = x.argsort().argsort(); ry = y.argsort().argsort()\n    rxm, rym = rx - rx.mean(), ry - ry.mean()\n    spear = float((rxm*rym).sum() / (np.sqrt((rxm**2).sum()*(rym**2).sum()) + 1e-12))\n    return pear, spear\n\ndef validate_influence_edges_sweep(model, G, scalers=None, eps_list=(0.1, 0.25, 0.5, 1.0), sign_tau=1e-5):\n    X, edges, E = to_features_device(G, scalers=scalers, requires_grad=True)\n    if hasattr(E, \"retain_grad\"): E.retain_grad()\n    with amp_context():\n        A0, _ = model([(X, edges, E)])[0]\n    A0 = float(A0.detach().cpu())\n\n    results = []\n    model.zero_grad(set_to_none=True)\n    Xg, edges_g, Eg = to_features_device(G, scalers=scalers, requires_grad=True)\n    if hasattr(Eg, \"retain_grad\"): Eg.retain_grad()\n    with amp_context():\n        A_hat, _ = model([(Xg, edges_g, Eg)])[0]\n    A_hat.backward(retain_graph=True)\n    ggrad = Eg.grad.detach().cpu().numpy()[:,2] if Eg.shape[1] >= 3 and Eg.grad is not None else np.zeros((len(edges),))\n\n    order = np.argsort(-np.abs(ggrad))\n    k_use = min(10, len(order))\n    ks = list(order[:k_use]) + list(order[-k_use:])\n\n    for eps in eps_list:\n        dA_pred, dA_meas = [], []\n        for k in ks:\n            i,j,_ = edges[k]\n            H = clone_graph(G)\n            old = H.edges[i,j].get(\"g_mem\", 1.0)\n            H.edges[i,j][\"g_mem\"] = float(old) + float(eps)\n            A1, _ = predict_graph_amp(model, H, scalers=scalers)\n            dA_meas.append(A1 - A0)\n            dA_pred.append(ggrad[k] * eps)\n        dA_pred = np.array(dA_pred); dA_meas = np.array(dA_meas)\n        mask = (np.abs(dA_pred) > sign_tau) & (np.abs(dA_meas) > sign_tau)\n        sign_agree = float((np.sign(dA_pred[mask]) == np.sign(dA_meas[mask])).mean()) if mask.any() else np.nan\n        pear, spear = safe_corr(dA_pred, dA_meas)\n        results.append({\"eps\":eps, \"pearson\":pear, \"spearman\":spear, \"sign_agree_masked\":sign_agree,\n                        \"mean_abs_dA_meas\": float(np.mean(np.abs(dA_meas)))})\n    res_df = pd.DataFrame(results)\n    res_df.to_csv(OUT_DIR / \"influence_edges_sweep.csv\", index=False)\n    return res_df\n\ndef ablate_gmem_and_measure(model, G, scalers=None, delta=+0.5):\n    H = clone_graph(G)\n    for (i,j) in H.edges():\n        H.edges[i,j][\"g_mem\"] = H.edges[i,j].get(\"g_mem\",0.0) + delta\n    A0,_ = predict_graph_amp(model, G, scalers=scalers)\n    A1,_ = predict_graph_amp(model, H, scalers=scalers)\n    return A1 - A0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:18:00.329802Z","iopub.execute_input":"2025-11-14T17:18:00.330118Z","iopub.status.idle":"2025-11-14T17:18:00.350244Z","shell.execute_reply.started":"2025-11-14T17:18:00.330101Z","shell.execute_reply":"2025-11-14T17:18:00.349485Z"}},"outputs":[],"execution_count":8},{"id":"220ef3a8","cell_type":"markdown","source":"## ğŸ·ï¸ Weak labels (noâ€‘ops)","metadata":{}},{"id":"13bddebf","cell_type":"code","source":"\ndef get_mavedb_first_scores_for(acc): \n    return None\n\ndef get_fireprot_labels_for(acc):\n    return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:18:00.351098Z","iopub.execute_input":"2025-11-14T17:18:00.351383Z","iopub.status.idle":"2025-11-14T17:18:00.363751Z","shell.execute_reply.started":"2025-11-14T17:18:00.351360Z","shell.execute_reply":"2025-11-14T17:18:00.363155Z"}},"outputs":[],"execution_count":9},{"id":"3e7005c6","cell_type":"markdown","source":"## ğŸ‹ï¸ Training with route + gradient alignment","metadata":{}},{"id":"dfee50f7","cell_type":"code","source":"\ndef _edge_flux_vector(G, edges, eps=1e-3):\n    Lp = laplacian_pinv_weighted(G, eps=eps)\n    n = G.number_of_nodes()\n    src = [0]; sink = [min(6, n-1)]\n    flux = prs_edge_flux(G, Lp, src, sink)\n    f = np.zeros((len(edges),), dtype=float)\n    for k,(i,j,_) in enumerate(edges):\n        f[k] = float(flux.get((i,j), flux.get((j,i), 0.0)))\n    if np.max(f) > 0:\n        f = f / (np.max(f) + 1e-12)\n    f = 0.05 + 0.95 * f\n    return f\n\ndef train_graph_regressor_amp_route(graphs, scalers, steps=300, lr=1e-3, weight_decay=1e-4, clip=1.0,\n                                    route_w=0.6, align_w=0.6):\n    cache = []\n    for (acc, pdbid, chain, G) in graphs:\n        X0, edges, E0 = to_features_device(G, scalers=scalers, requires_grad=False)\n        f = _edge_flux_vector(G, edges, eps=LAPLACE_EPS)\n        cache.append((acc, pdbid, chain, G, edges, f))\n\n    X0,_,E0 = to_features_device(graphs[0][3], scalers=scalers, requires_grad=False)\n    model = GraphBatchNetAMP(X0.shape[1], E0.shape[1]).to(DEVICE)\n    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scaler = maybe_scaler()\n\n    huber = torch.nn.SmoothL1Loss()\n\n    pbar = tqdm(range(steps), desc=\"Training(route)\", leave=True)\n    for step in pbar:\n        model.train(); opt.zero_grad(set_to_none=True)\n        idx = np.random.choice(len(cache), min(4, len(cache)), replace=False)\n        feats, route_targets = [], []\n        for ii in idx:\n            (acc, pdbid, chain, G, edges, flux_vec) = cache[ii]\n            X, edges_t, E = to_features_device(G, scalers=scalers, requires_grad=True)\n            feats.append((X,edges_t,E))\n            route_targets.append(torch.tensor(flux_vec, dtype=torch.float32, device=DEVICE))\n\n        with amp_context():\n            y = model(feats)\n            loss_main = (y[:,0]**2).mean() * 0.0\n\n            route_loss = 0.0\n            for (X,edges_t,E), flux_t in zip(feats, route_targets):\n                if E.shape[1] >= 3 and E.shape[0] > 0:\n                    g_raw = E[:,2:3]\n                    gate  = torch.clamp(1.0 + model.gate_scale * g_raw, 0.0, 8.0)\n                    gate01 = (gate - gate.min()) / (gate.max() - gate.min() + 1e-6)\n                    route_loss = route_loss + huber(gate01.squeeze(-1), flux_t)\n\n            align_loss = 0.0\n            for (X,edges_t,E), flux_t in zip(feats, route_targets):\n                if E.shape[1] >= 3 and E.shape[0] > 0:\n                    Ah,_ = model([(X,edges_t,E)])[0]\n                    grads = torch.autograd.grad(Ah, E, retain_graph=True, create_graph=True, allow_unused=True)[0]\n                    if grads is None: continue\n                    g = grads[:,2].abs()\n                    g_norm = g / (g.max() + 1e-6)\n                    align_loss = align_loss + huber(g_norm, flux_t)\n\n            loss = loss_main + route_w * route_loss + align_w * align_loss\n\n        if scaler:\n            scaler.scale(loss).backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n            scaler.step(opt); scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n            opt.step()\n\n        pbar.set_postfix({\"loss\": float(loss.detach().cpu()),\n                          \"route\": float((route_w*route_loss).detach().cpu()) if isinstance(route_loss, torch.Tensor) else 0.0,\n                          \"align\": float((align_w*align_loss).detach().cpu()) if isinstance(align_loss, torch.Tensor) else 0.0})\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:18:00.365487Z","iopub.execute_input":"2025-11-14T17:18:00.365687Z","iopub.status.idle":"2025-11-14T17:18:00.383159Z","shell.execute_reply.started":"2025-11-14T17:18:00.365672Z","shell.execute_reply":"2025-11-14T17:18:00.382343Z"}},"outputs":[],"execution_count":10},{"id":"b1f2cddd","cell_type":"markdown","source":"## ğŸš€ Driver","metadata":{}},{"id":"d550f448","cell_type":"code","source":"\nTARGET_TERMS = [\"TP53\", \"LYSOZYME\", \"TEM-1\", \"DHFR\", \"HSP90\"]\n\nacc_all = collect_uniprot_via_terms(TARGET_TERMS, size=3)\n\nsel = uniprot_to_structures(acc_all, cap=N_STRUCTURES)\ndisplay(sel.head())\nsel = sel.dropna(subset=[\"uniprot\"]).reset_index(drop=True)\nsel = download_structures_df(sel)\nprint(\"Downloaded:\", len(sel))\n\ngraphs = []\nfor _,row in tqdm(sel.iterrows(), total=len(sel), desc=\"Building graphs\"):\n    try:\n        res = parse_cif_to_residues(Path(row[\"cif_path\"]), chain_id=row.get(\"chain_id\") or None)\n        if len(res) < 8:\n            continue\n        G = build_topk_graph(res, topk=TOPK_PER_NODE, min_sep=MIN_SEQ_SEP, sigma=SIGMA_CONTACT_A)\n        Lp = laplacian_pinv_weighted(G, eps=LAPLACE_EPS)\n        flux = prs_edge_flux(G, Lp, [0], [min(6, len(res)-1)])\n        adapt_conductance(G, flux, alpha=0.3, key=\"g_mem\", base=1.0)\n        normalize_gmem_01_with_jitter(G, jitter=1e-3)\n        G.graph[\"uniprot\"]=row[\"uniprot\"]; G.graph[\"pdb_id\"]=row.get(\"pdb_id\",\"\") or \"\"; G.graph[\"chain\"]=row.get(\"chain_id\",\"\") or \"\"\n        graphs.append((row[\"uniprot\"], row.get(\"pdb_id\"), row.get(\"chain_id\"), G))\n    except Exception as e:\n        print(\"Graph build failed:\", row.to_dict(), e)\nprint(\"Graphs built:\", len(graphs))\n\nSCALERS = fit_scalers(graphs)\nprint(\"Fitted scalers â€” node:\", SCALERS[\"node_mean\"].shape, \"edge:\", SCALERS[\"edge_mean\"].shape)\n\nif not RUN_PIPELINE or len(graphs)==0:\n    print(\"Pipeline heavy steps are disabled. Set RUN_PIPELINE=True to execute training and scans.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:18:00.384046Z","iopub.execute_input":"2025-11-14T17:18:00.384574Z","iopub.status.idle":"2025-11-14T17:18:17.750896Z","shell.execute_reply.started":"2025-11-14T17:18:00.384555Z","shell.execute_reply":"2025-11-14T17:18:17.750137Z"}},"outputs":[{"name":"stdout","text":"UniProt candidates: 15 ['P00374', 'P00375', 'P00698', 'P38987', 'P41887', 'P46598', 'P61626', 'P62593', 'P70399', 'Q12888', 'Q18688', 'Q920D2', 'Q9D925', 'Q9H2S6', 'Q9Y2B4']\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  uniprot pdb_id chain_id  coverage  resolution source\n0  P00374   4M6J        A     1.000       1.201    PDB\n1  P00375   3D80        A     0.995       1.400    PDB\n2  P00698   2VB1        A     1.000       0.650    PDB\n3  P38987   None                NaN         NaN   AFDB\n4  P41887   None                NaN         NaN   AFDB","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uniprot</th>\n      <th>pdb_id</th>\n      <th>chain_id</th>\n      <th>coverage</th>\n      <th>resolution</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P00374</td>\n      <td>4M6J</td>\n      <td>A</td>\n      <td>1.000</td>\n      <td>1.201</td>\n      <td>PDB</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P00375</td>\n      <td>3D80</td>\n      <td>A</td>\n      <td>0.995</td>\n      <td>1.400</td>\n      <td>PDB</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P00698</td>\n      <td>2VB1</td>\n      <td>A</td>\n      <td>1.000</td>\n      <td>0.650</td>\n      <td>PDB</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P38987</td>\n      <td>None</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AFDB</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P41887</td>\n      <td>None</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AFDB</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stderr","text":"Downloading structures: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Downloaded: 6\n","output_type":"stream"},{"name":"stderr","text":"Building graphs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.68it/s]","output_type":"stream"},{"name":"stdout","text":"Graphs built: 6\nFitted scalers â€” node: (1, 24) edge: (1, 3)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"id":"1fa50bfb","cell_type":"code","source":"\nif RUN_PIPELINE and len(graphs)>0:\n    model = train_graph_regressor_amp_route(\n        graphs, SCALERS, steps=TRAIN_STEPS, lr=1e-3, weight_decay=1e-4, clip=1.0,\n        route_w=0.6, align_w=0.6\n    )\n\n    X, edges0, E = to_features_device(graphs[0][3], scalers=SCALERS, requires_grad=True)\n    print(\"g_mem stats (first graph): min/max/std =\", float(E[:,2].min()), float(E[:,2].max()), float(E[:,2].std()))\n\n    dA_pos = ablate_gmem_and_measure(model, graphs[0][3], scalers=SCALERS, delta=+0.5)\n    dA_neg = ablate_gmem_and_measure(model, graphs[0][3], scalers=SCALERS, delta=-0.5)\n    print(\"Î”A (+0.5 g_mem):\", dA_pos)\n    print(\"Î”A (-0.5 g_mem):\", dA_neg)\n\n    if abs(dA_pos) < 1e-6 and abs(dA_neg) < 1e-6:\n        with torch.no_grad():\n            model.gate_scale.copy_(model.gate_scale * 2.0)\n        dA_pos = ablate_gmem_and_measure(model, graphs[0][3], scalers=SCALERS, delta=+0.5)\n        dA_neg = ablate_gmem_and_measure(model, graphs[0][3], scalers=SCALERS, delta=-0.5)\n        print(\"[auto-boost gate_scale] Î”A (+/-0.5) ->\", dA_pos, dA_neg)\n\n    Gtoy = deepcopy(graphs[0][3])\n    for (i,j) in Gtoy.edges(): Gtoy.edges[i,j][\"g_mem\"] = np.random.uniform(0.0, 1.0)\n    Xtoy, edgetoy, Etoy = to_features_device(Gtoy, scalers=SCALERS, requires_grad=True)\n    if hasattr(Etoy, \"retain_grad\"): Etoy.retain_grad()\n    with amp_context():\n        Ah,_ = model([(Xtoy,edgetoy,Etoy)])[0]\n    model.zero_grad(set_to_none=True); Ah.backward()\n    toy_grad = Etoy.grad[:,2].abs().mean().item() if Etoy.grad is not None else 0.0\n    print(\"Mean |âˆ‚A/âˆ‚g_mem| (toy):\", toy_grad)\n\n    if toy_grad < 1e-6:\n        with torch.no_grad():\n            model.gate_scale.copy_(model.gate_scale * 2.0)\n        Xtoy, edgetoy, Etoy = to_features_device(Gtoy, scalers=SCALERS, requires_grad=True)\n        if hasattr(Etoy, \"retain_grad\"): Etoy.retain_grad()\n        with amp_context():\n            Ah,_ = model([(Xtoy,edgetoy,Etoy)])[0]\n        model.zero_grad(set_to_none=True); Ah.backward()\n        toy_grad = Etoy.grad[:,2].abs().mean().item() if Etoy.grad is not None else 0.0\n        print(\"[auto-boost gate_scale] Mean |âˆ‚A/âˆ‚g_mem| (toy):\", toy_grad)\n\n    uni,pdbid,chain,G = graphs[0]\n    scan_df, scan_path = mutational_scan_amp(model, G, scalers=SCALERS, uni=uni, pdbid=pdbid, chain=chain, reward_w=(W1_A,W2_DDG,W5_MUT))\n    print(\"Scan saved:\", scan_path)\n    node_inf, edge_inf, node_p, edge_p = influence_scores_amp(model, G, scalers=SCALERS)\n    print(\"Influence saved:\", node_p, edge_p)\n\n    sweep = validate_influence_edges_sweep(model, G, scalers=SCALERS, eps_list=[0.1,0.25,0.5,1.0], sign_tau=1e-5)\n    display(sweep.head())\n    print(\"Saved sweep:\", OUT_DIR / \"influence_edges_sweep.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:18:17.751535Z","iopub.execute_input":"2025-11-14T17:18:17.751781Z","iopub.status.idle":"2025-11-14T18:44:53.808954Z","shell.execute_reply.started":"2025-11-14T17:18:17.751761Z","shell.execute_reply":"2025-11-14T18:44:53.808145Z"}},"outputs":[{"name":"stderr","text":"Training(route): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [1:09:38<00:00, 13.93s/it, loss=0.00558, route=0.00228, align=0.0033] \n","output_type":"stream"},{"name":"stdout","text":"g_mem stats (first graph): min/max/std = -0.0017542921705171466 1.0012023448944092 0.10249041020870209\nÎ”A (+0.5 g_mem): -0.4362640380859375\nÎ”A (-0.5 g_mem): 0.016553878784179688\nMean |âˆ‚A/âˆ‚g_mem| (toy): 0.0017881251405924559\n","output_type":"stream"},{"name":"stderr","text":"Scan positions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [16:29<00:00,  5.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Scan saved: /kaggle/working/outputs/mutational_scan_P00374_amp.csv\nInfluence saved: /kaggle/working/outputs/influence_nodes_P00374_4M6J_A_amp.csv /kaggle/working/outputs/influence_edges_P00374_4M6J_A_amp.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    eps   pearson  spearman  sign_agree_masked  mean_abs_dA_meas\n0  0.10 -0.103363 -0.039098                0.6          0.001527\n1  0.25 -0.034799  0.097744                0.8          0.001794\n2  0.50 -0.223166 -0.163910                0.7          0.001504\n3  1.00  0.167298  0.187970                0.9          0.003175","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eps</th>\n      <th>pearson</th>\n      <th>spearman</th>\n      <th>sign_agree_masked</th>\n      <th>mean_abs_dA_meas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.10</td>\n      <td>-0.103363</td>\n      <td>-0.039098</td>\n      <td>0.6</td>\n      <td>0.001527</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.25</td>\n      <td>-0.034799</td>\n      <td>0.097744</td>\n      <td>0.8</td>\n      <td>0.001794</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.50</td>\n      <td>-0.223166</td>\n      <td>-0.163910</td>\n      <td>0.7</td>\n      <td>0.001504</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.00</td>\n      <td>0.167298</td>\n      <td>0.187970</td>\n      <td>0.9</td>\n      <td>0.003175</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Saved sweep: /kaggle/working/outputs/influence_edges_sweep.csv\n","output_type":"stream"}],"execution_count":12},{"id":"7303322c-96b9-4138-ac82-30c547360d67","cell_type":"code","source":"def pick_eps(model, G, target=0.002, start=0.1):\n    eps = start\n    while eps <= 1.5:\n        df = validate_influence_edges_sweep(model, G, eps_list=[eps], sign_tau=1e-5)\n        if float(df[\"mean_abs_dA_meas\"].iloc[0]) >= target:\n            return eps\n        eps *= 1.5\n    return eps\neps_star = pick_eps(model, G)\nprint(\"Chosen eps:\", eps_star)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:52:39.717682Z","iopub.execute_input":"2025-11-14T18:52:39.718252Z","iopub.status.idle":"2025-11-14T18:52:45.736130Z","shell.execute_reply.started":"2025-11-14T18:52:39.718229Z","shell.execute_reply":"2025-11-14T18:52:45.735342Z"}},"outputs":[{"name":"stdout","text":"Chosen eps: 0.1\n","output_type":"stream"}],"execution_count":15},{"id":"1445891c-4f34-4033-8904-762e44088f29","cell_type":"code","source":"# --- Fallback: rank edges by |âˆ‚A/âˆ‚g_mem| if edge_grad_rank isn't defined ---\ndef edge_grad_rank(model, G, head=\"A\"):\n    X, edges, E = to_features_device(G, requires_grad=True)\n    if hasattr(E, \"retain_grad\"): E.retain_grad()\n    with amp_context():\n        A_hat, ddG_hat = model([(X, edges, E)])[0]\n    model.zero_grad(set_to_none=True)\n    (A_hat if head==\"A\" else ddG_hat).backward(retain_graph=True)\n    g = E.grad[:, 2].detach().abs().cpu().numpy() if E.shape[1] >= 3 else None\n    if g is None:\n        return []\n    order = g.argsort()[::-1]  # descending\n    return order\n\n# --- Ablation by edge-rank: bump g_mem on top vs bottom edges and measure Î”A ---\ndef ablate_edges_by_rank(model, G, k=10, eps=0.5):\n    A0, _ = predict_graph_amp(model, G)\n    order = edge_grad_rank(model, G, head=\"A\")\n    if len(order) == 0:\n        print(\"No edge gradients available (E has <3 columns or no grad path).\")\n        return\n    for label, idxs in [(\"top\", order[:k]), (\"bottom\", order[-k:])]:\n        H = clone_graph(G)\n        XH, edgesH, EH = to_features_device(H)  # to align indices\n        for eidx in idxs:\n            i, j, _ = edgesH[eidx]\n            H.edges[i, j][\"g_mem\"] = H.edges[i, j].get(\"g_mem\", 0.0) + float(eps)\n        A1, _ = predict_graph_amp(model, H)\n        print(f\"{label}  Î”A = {float(A1 - A0):.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:55:05.996023Z","iopub.execute_input":"2025-11-14T18:55:05.996874Z","iopub.status.idle":"2025-11-14T18:55:06.006235Z","shell.execute_reply.started":"2025-11-14T18:55:05.996838Z","shell.execute_reply":"2025-11-14T18:55:06.005505Z"}},"outputs":[],"execution_count":18},{"id":"ab8efcb1-5b4f-4041-adf7-4025e1c91e61","cell_type":"code","source":"# Pick the first graph (same one you used for scans)\nuni, pdbid, chain, G = graphs[0]\nprint(\"Running ablation on:\", uni, pdbid, chain)\nablate_edges_by_rank(model, G, k=10, eps=0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:55:09.502677Z","iopub.execute_input":"2025-11-14T18:55:09.503413Z","iopub.status.idle":"2025-11-14T18:55:11.242258Z","shell.execute_reply.started":"2025-11-14T18:55:09.503383Z","shell.execute_reply":"2025-11-14T18:55:11.241499Z"}},"outputs":[{"name":"stdout","text":"Running ablation on: P00374 4M6J A\ntop  Î”A = -0.008354\nbottom  Î”A = -0.006187\n","output_type":"stream"}],"execution_count":19}]}